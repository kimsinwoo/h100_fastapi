"""
Production-grade Z-Image-Turbo img2img service
Optimized for quality, stability, and commercial deployment
"""

from __future__ import annotations

# Z-Image íŒŒì´í”„ë¼ì¸ import ì‹œ JITCallable._set_src() ì˜¤ë¥˜ ë°©ì§€ (PyTorch JIT/compile í˜¸í™˜ì„±)
import os
os.environ.setdefault("PYTORCH_JIT", "0")
os.environ.setdefault("TORCH_COMPILE_DISABLE", "1")

import asyncio
import io
import logging
import time
import warnings
from typing import Any

from app.core.config import get_settings
from app.models.image_prompt_expert import ImagePromptExpert

logger = logging.getLogger(__name__)

_pipeline: Any = None
_lock = asyncio.Lock()
_device: Any = None

# ===== Z-Image-Turbo ê¶Œì¥ê°’ =====
# guidance_scale=0 ì´ë©´ negative_promptëŠ” ë¬´ì‹œë¨(ê³µì‹ ë¬¸ì„œ). í”½ì…€ì•„íŠ¸ë§Œ 1.8ë¡œ ì˜¬ë ¤ ë„¤ê±°í‹°ë¸Œ ì ìš©.
DEFAULT_GUIDANCE_SCALE = 0.0
PIXEL_ART_GUIDANCE_SCALE = 1.8  # í”½ì…€ì•„íŠ¸: voxel/3D ë¸”ë¡ ì°¨ë‹¨í•˜ë ¤ë©´ 1 ì´ìƒ í•„ìš”
DEFAULT_NUM_INFERENCE_STEPS = 8
MODEL_RESOLUTION = 1024

# ìŠ¤íƒ€ì¼ë³„ strength: í”½ì…€ì•„íŠ¸ëŠ” ë‚®ì¶°ì•¼ 3D ë¸”ë¡/ë³µì…€ ë°©ì§€, ë‚˜ë¨¸ì§€ëŠ” ê° íŠ¹ì„± ìœ ì§€
STRENGTH_BY_STYLE: dict[str, tuple[float, float]] = {
    "pixel art": (0.36, 0.46),      # ë§¤ìš° ë‚®ê²Œ ìœ ì§€í•´ì•¼ ìˆœìˆ˜ 2D ìŠ¤í”„ë¼ì´íŠ¸ë§Œ ë‚˜ì˜´
    "anime": (0.48, 0.56),
    "realistic": (0.46, 0.56),
    "watercolor": (0.48, 0.56),
    "cyberpunk": (0.48, 0.56),
    "oil painting": (0.48, 0.56),
    "sketch": (0.48, 0.56),
    "cinematic": (0.46, 0.54),
    "fantasy art": (0.48, 0.56),
    "3d render": (0.50, 0.58),
}
DEFAULT_STRENGTH_FALLBACK = 0.50
STRENGTH_GLOBAL_MAX = 0.58

# í”½ì…€ ì•„íŠ¸ ì„ íƒ ì‹œ ë„¤ê±°í‹°ë¸Œì— ì¶”ê°€ë¡œ ë„£ì–´ 3D/ë³µì…€ ì™„ì „ ì°¨ë‹¨
PIXEL_ART_NEGATIVE_SUFFIX = (
    ", voxel art, 3D pixel art, blocky 3D, Minecraft style, lego style, "
    "sweater made of blocks, dog made of cubes, volumetric blocks, 2.5D"
)

# ìˆœìˆ˜ 2D í”½ì…€ ì•„íŠ¸ë§Œ (ë§ˆì¸í¬ë˜í”„íŠ¸/ë³µì…€/3D ë¸”ë¡ ì™„ì „ ë°°ì œ)
# ============================================================
# Device
# ============================================================

def _resolve_device():
    import torch
    if torch.cuda.is_available():
        return torch.device("cuda")
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")


# ============================================================
# Load Pipeline
# ============================================================

def _load_pipeline_sync():
    global _pipeline, _device

    import os
    # JITCallable._set_src() í˜¸í™˜ì„± ì˜¤ë¥˜ ë°©ì§€: diffusers Z-Image ë¡œë“œ ì „ì— JIT/compile ë¹„í™œì„±í™”
    os.environ.setdefault("PYTORCH_JIT", "0")
    os.environ.setdefault("TORCH_COMPILE_DISABLE", "1")

    import torch
    # torch.compile ì‚¬ìš© ì‹œ ì¼ë¶€ í™˜ê²½ì—ì„œ JIT ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ â†’ ë¹„í™œì„±í™”
    if getattr(torch, "_dynamo", None) and getattr(torch._dynamo, "config", None):
        try:
            torch._dynamo.config.suppress_errors = True
        except Exception:
            pass

    # xformers + Triton 3.x í˜¸í™˜ ì˜¤ë¥˜(JITCallable._set_src) íšŒí”¼: xformers ë¯¸ì‚¬ìš©ìœ¼ë¡œ ë¡œë“œ
    try:
        import diffusers.utils.import_utils as diffusers_import_utils
        diffusers_import_utils.is_xformers_available = lambda: False
    except Exception:
        pass

    try:
        from diffusers import ZImageImg2ImgPipeline
    except ImportError as e:
        err_msg = str(e)
        if "JITCallable" in err_msg or "_set_src" in err_msg:
            logger.exception("Z-Image pipeline import failed (JIT/torch compatibility): %s", e)
            raise RuntimeError(
                "Z-Image íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘ JIT í˜¸í™˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
                "ì„œë²„ ì‹œì‘ ì „ì— ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”: "
                "PYTORCH_JIT=0 TORCH_COMPILE_DISABLE=1"
            ) from e
        logger.error(
            "ZImageImg2ImgPipeline not found. Z-Image-Turbo requires diffusers from git: "
            "pip install git+https://github.com/huggingface/diffusers.git -U (error: %s)",
            e,
        )
        raise RuntimeError(
            "Z-Image-Turbo íŒŒì´í”„ë¼ì¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "diffusers ìµœì‹  ë²„ì „ì´ í•„ìš”í•©ë‹ˆë‹¤: pip install git+https://github.com/huggingface/diffusers.git -U"
        ) from e
    except Exception as e:
        err_msg = str(e)
        if "JITCallable" in err_msg or "_set_src" in err_msg:
            logger.exception("Z-Image pipeline import failed (JIT/torch compatibility): %s", e)
            raise RuntimeError(
                "Z-Image íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘ JIT í˜¸í™˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
                "ì„œë²„ ì‹œì‘ ì „ì— ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”: "
                "PYTORCH_JIT=0 TORCH_COMPILE_DISABLE=1"
            ) from e
        raise

    settings = get_settings()
    _device = _resolve_device()

    dtype = torch.bfloat16 if (_device.type == "cuda" and getattr(torch, "bfloat16", None)) else torch.float32

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")

        try:
            pipe = ZImageImg2ImgPipeline.from_pretrained(
                settings.model_id,
                torch_dtype=dtype,
                low_cpu_mem_usage=True,
            )
        except Exception as e:
            logger.exception("Failed to load model %s: %s", settings.model_id, e)
            raise RuntimeError(
                f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {settings.model_id}. "
                "ì¸í„°ë„· ì—°ê²°Â·Hugging Face ì ‘ê·¼Â·ë””ìŠ¤í¬ ê³µê°„ì„ í™•ì¸í•˜ì„¸ìš”. "
                "diffusersëŠ” pip install git+https://github.com/huggingface/diffusers.git ë¡œ ì„¤ì¹˜ ê¶Œì¥."
            ) from e

        for method_name in ("enable_attention_slicing", "enable_vae_slicing", "enable_vae_tiling"):
            method = getattr(pipe, method_name, None)
            if callable(method):
                try:
                    method()
                except Exception:
                    pass

        pipe = pipe.to(_device)

    logger.info(
        "Pipeline loaded on %s (dtype=%s)",
        _device,
        dtype,
    )

    _pipeline = pipe
    return pipe


async def get_pipeline():
    global _pipeline
    async with _lock:
        if _pipeline is None:
            loop = asyncio.get_event_loop()
            _pipeline = await loop.run_in_executor(
                None, _load_pipeline_sync
            )
        return _pipeline


# ============================================================
# Inference
# ============================================================

def _resize_keep_ratio(in_w: int, in_h: int, max_side: int) -> tuple[int, int]:
    """ì…ë ¥ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ê¸´ ë³€ì´ max_side ì´í•˜, 8ì˜ ë°°ìˆ˜ë¡œ (out_w, out_h) ê³„ì‚°."""
    if in_w <= 0 or in_h <= 0:
        return (max_side, max_side)
    scale = max_side / max(in_w, in_h)
    out_w = max(64, min(max_side, round(in_w * scale)))
    out_h = max(64, min(max_side, round(in_h * scale)))
    out_w = (out_w // 8) * 8
    out_h = (out_h // 8) * 8
    return (max(64, out_w), max(64, out_h))


def _run_inference_sync(
    image_bytes: bytes,
    prompt: str,
    negative_prompt: str,
    strength: float,
    num_steps: int,
    guidance_scale: float,
    width: int,
    height: int,
    seed: int | None,
) -> bytes:

    import torch
    from PIL import Image

    global _pipeline, _device

    if _pipeline is None:
        raise RuntimeError("Pipeline not loaded")

    img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    target_w, target_h = width, height
    if img.width != target_w or img.height != target_h:
        img = img.resize((target_w, target_h), Image.Resampling.LANCZOS)

    # Deterministic seed
    generator = torch.Generator(device=_device)
    if seed is not None:
        generator.manual_seed(seed)

    logger.info(
        "Running img2img | steps=%d | guidance=%.2f | strength=%.2f",
        num_steps,
        guidance_scale,
        strength,
    )

    with torch.inference_mode():
        result = _pipeline(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=img,
            strength=strength,
            num_inference_steps=num_steps,
            guidance_scale=guidance_scale,
            generator=generator,
            output_type="pil",   # ğŸ”¥ Let diffusers handle decoding
        )

    image = result.images[0]

    buf = io.BytesIO()
    image.save(buf, format="PNG")
    return buf.getvalue()


# ============================================================
# Public API
# ============================================================

async def run_image_to_image(
    image_bytes: bytes,
    style_key: str,
    custom_prompt: str | None = None,
    strength: float | None = None,
    num_steps: int | None = None,
    size: int | None = None,
    seed: int | None = None,
):

    pipe = await get_pipeline()
    if pipe is None:
        raise RuntimeError("Model not available")

    settings = get_settings()
    style_lower = style_key.lower().strip()

    # ImagePromptExpert + êµ¬ì„± ìœ ì§€ (ë³µì¡í•œ ì‚¬ì§„ë„ ë ˆì´ì•„ì›ƒ ìœ ì§€)
    compiled = ImagePromptExpert.compile(
        style_key, custom_prompt or "", aspect_ratio="1:1"
    )
    prompt = compiled["final_prompt"]
    prompt += (
        ", high detail, sharp focus, preserve fine details and texture, "
        "preserve original composition, same layout and pose, keep subject arrangement, "
        "same subject(s) as reference image, same number of figures or animals, do not change to human or one character"
    )
    negative_prompt = compiled["negative_prompt"]
    if "pixel" in style_lower:
        negative_prompt = negative_prompt + PIXEL_ART_NEGATIVE_SUFFIX

    # ìŠ¤íƒ€ì¼ë³„ strength ìƒí•œÂ·ê¸°ë³¸ê°’
    default_st, max_st = STRENGTH_BY_STYLE.get(
        style_lower, (DEFAULT_STRENGTH_FALLBACK, STRENGTH_GLOBAL_MAX)
    )
    strength = strength if strength is not None else default_st
    strength = max(0.0, min(STRENGTH_GLOBAL_MAX, min(1.0, strength), max_st))

    num_steps = max(1, min(50, num_steps or DEFAULT_NUM_INFERENCE_STEPS))
    guidance_scale = PIXEL_ART_GUIDANCE_SCALE if "pixel" in style_lower else DEFAULT_GUIDANCE_SCALE

    max_side = size or MODEL_RESOLUTION
    from PIL import Image
    with Image.open(io.BytesIO(image_bytes)) as tmp:
        tmp.load()
        in_w, in_h = tmp.width, tmp.height
    target_w, target_h = _resize_keep_ratio(in_w, in_h, max_side)

    loop = asyncio.get_event_loop()
    start = time.perf_counter()

    result = await loop.run_in_executor(
        None,
        lambda: _run_inference_sync(
            image_bytes,
            prompt,
            negative_prompt,
            strength,
            num_steps,
            guidance_scale,
            target_w,
            target_h,
            seed,
        ),
    )

    elapsed = time.perf_counter() - start
    return result, elapsed


# ============================================================
# Utilities
# ============================================================

def is_pipeline_loaded() -> bool:
    return _pipeline is not None


def is_gpu_available() -> bool:
    try:
        import torch
        return torch.cuda.is_available()
    except Exception:
        return False
