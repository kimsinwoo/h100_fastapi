# App
APP_NAME=Z-Image AI Service
DEBUG=false
ENVIRONMENT=development

# Server
HOST=0.0.0.0
PORT=7000
# 리버스 프록시 하위 경로일 때 (프론트 baseURL과 일치). 예: 95ce287337c3ad9f
# BASE_PATH=95ce287337c3ad9f

# Paths (relative to backend dir)
STATIC_DIR=static
GENERATED_DIR_NAME=generated
UPLOAD_MAX_SIZE_MB=20

# 이미지 생성: OmniGen(Omni) 사용 시 H100 등에서 Omni 모델 로드 (기본값 true)
USE_OMNIGEN=true
OMNIGEN_MODEL_ID=Shitao/OmniGen-v1-diffusers
# USE_OMNIGEN=false 로 두면 Z-Image-Turbo 사용

# Z-Image model (USE_OMNIGEN=false 일 때만 사용)
MODEL_ID=Tongyi-MAI/Z-Image-Turbo
DEVICE_PREFERENCE=auto
DEFAULT_STRENGTH=0.6
DEFAULT_STEPS=9
DEFAULT_SIZE=1024
USE_AUTOCAST=true

# CORS (comma-separated origins; * for all)
CORS_ORIGINS=*
CORS_ALLOW_CREDENTIALS=true

# Rate limiting (동시 100명 사용 시 100~200 권장)
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_SECONDS=60

# LLM — 로컬(transformers) 또는 vLLM API
LLM_ENABLED=true
# 로컬: 동시 1건만. 100명 쓰려면 vLLM 사용 (아래 LLM_USE_LOCAL=false)
LLM_USE_LOCAL=true
LLM_LOCAL_MODEL_ID=openai/gpt-oss-20b
# LLM_HF_TOKEN=  ← Hugging Face 게이트일 때만
LLM_TIMEOUT_SECONDS=120
LLM_MAX_CONCURRENT=1
# ---- 100명 동시 사용: vLLM 서버(7001) 사용 시 ----
# LLM_USE_LOCAL=false
# LLM_API_BASE=http://127.0.0.1:7001/v1
# LLM_MAX_CONCURRENT=100
